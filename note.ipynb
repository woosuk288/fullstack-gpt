{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi\\nAI: How are you?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=4)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(1, 1)\n",
    "\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "add_message(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Wooseok, I live in South Korea\", \"Wow that is so cool!\")\n",
    "add_message(\"한국은 정말 멋진 곳이야.\", \"나도 갈 수 있으면 좋을텐데...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as Wooseok from South Korea. The AI responds with enthusiasm, saying it's cool. Wooseok mentions that South Korea is a really cool place. The AI expresses a desire to visit South Korea if possible.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소주는 주로 쌀을 발효시켜 만들어집니다. 먼저 쌀을 씻고 증기를 통해 살균시킨 후 발효용 누룩과 물을 섞어 발효시킵니다. 발효과정을 거친 뒤 증류기를 통해 증류하여 순수한 술을 얻습니다. 이후 술을 숙성시켜 맛을 부드럽게 만들고 필요에 따라 물을 섞어 알코올 도수를 조절합니다. 이렇게 만들어진 소주는 병에 담겨 판매되거나 바로 소비됩니다. \n",
      " 빵을 만드는 과정은 다음과 같습니다:\n",
      "\n",
      "1. 재료 준비: 밀가루, 물, 이스트, 설탕, 소금, 버터 등의 재료를 준비합니다.\n",
      "\n",
      "2. 반죽: 밀가루, 이스트, 물, 설탕, 소금을 섞어 반죽을 만듭니다. 이때 반죽이 부드럽고 탄력이 있도록 충분히 섞어야 합니다.\n",
      "\n",
      "3. 발효: 반죽을 따뜻한 곳에 두어 이스트가 발효되도록 합니다. 이스트가 발효되면 반죽이 부풀어 오르고 부드러워집니다.\n",
      "\n",
      "4. 성형: 발효된 반죽을 모양을 만들어 성형합니다. 다양한 모양의 빵을 만들 수 있습니다.\n",
      "\n",
      "5. 굽기: 성형된 반죽을 오븐에 넣어 굽습니다. 올바른 온도와 시간에 굽어야 빵이 완성됩니다.\n",
      "\n",
      "6. 냉각: 굽은 빵을 꺼내어 식힙니다. 빵이 식으면서 바삭하고 부드러워집니다.\n",
      "\n",
      "7. 마무리: 빵을 장식하거나 필요에 따라 버터나 잼을 발라서 완성합니다.\n",
      "\n",
      "이렇게 만들어진 빵은 다양한 종류의 빵으로 즐길 수 있습니다. \n",
      "\n",
      "Tokens Used: 676\n",
      "\tPrompt Tokens: 41\n",
      "\tCompletion Tokens: 635\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0013315\n"
     ]
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True, callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"소주는 어떻게 만드니?\")\n",
    "    b = chat.predict(\"빵은 어떻게 만드니?\")\n",
    "    print(a, \"\\n\", b, \"\\n\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woosu\\Dev\\python\\fullstack-gpt\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\woosu\\Dev\\python\\fullstack-gpt\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-4o-mini', model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "# chat = OpenAI(temperature=0.1, max_tokens=450, model=\"gpt-4o-mini\")\n",
    "\n",
    "# chat.save(\"model.json\")\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
